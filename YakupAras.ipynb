{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8356de88-942d-4dc4-bb92-f39953795199",
   "metadata": {},
   "source": [
    "**1- Normalizasyon**\n",
    "  Veri setinizi normalleştirmek, farklı ölçeklerde olan özelliklerin modeller tarafından daha etkili bir şekilde işlenmesini sağlar. Bu, özellikle uzaklık tabanlı algoritmalar için önemlidir, çünkü özellikler arasındaki ölçek farklılıkları modelin performansını doğrudan etkileyebilir. En yaygın normalleştirme yöntemlerinden biri Min-Max normalleştirmesidir. Bu yöntem, tüm değerleri 0 ile 1 arasında bir ölçeğe dönüştürür. Burada, veri setinizdeki her bir özelliği (sütunu) aşağıdaki formülü kullanarak normalleştirelim:\n",
    "\n",
    " **Xnor= (X-Xmin)/(Xmax - Xmin)**\n",
    "\n",
    "Xnor normalleştirilmiş değeri,\r\n",
    "X verinin orjinal değeri,\r\n",
    "Xmin veri setindeki en düşük değeri,\r\n",
    "Xmax veri setindeki en büyük değeri \n",
    "\r\n",
    "Bu işlemi Python'da pandas kütüphanesi kullanarak gerçekleştirebiliriz. Öncelikle, veri setinizi bir pandas DataFrame'e yükleyelim ve ardından Min-Max normalleştirmesini uygulayalım. Bunun için öncelikle veri setinizi gözden geçirelim ve normalleştirmeyi gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80cb3c6-6e8a-428f-afc4-908bd8507e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
       "0                  0.352941  0.743719       0.590164       0.353535  0.000000   \n",
       "1                  0.058824  0.427136       0.540984       0.292929  0.000000   \n",
       "2                  0.470588  0.919598       0.524590       0.000000  0.000000   \n",
       "3                  0.058824  0.447236       0.540984       0.232323  0.111111   \n",
       "4                  0.000000  0.688442       0.327869       0.353535  0.198582   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction       Age  Outcome  \n",
       "0  0.500745                  0.234415  0.483333      1.0  \n",
       "1  0.396423                  0.116567  0.166667      0.0  \n",
       "2  0.347243                  0.253629  0.183333      1.0  \n",
       "3  0.418778                  0.038002  0.000000      0.0  \n",
       "4  0.642325                  0.943638  0.200000      1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini doğru ayırıcı ile yükleyelim\n",
    "df = pd.read_csv('veri-seti.txt', header=None, sep='\\t')\n",
    "# Sütun adlarını belirleme\n",
    "columns = ['Number of times pregnant', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "df.columns = columns\n",
    "\n",
    "# Min-Max Normalizasyonu uygulayalım\n",
    "df_normalized = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# İlk beş satırı kontrol edelim\n",
    "df_normalized.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b305ee-95b9-4b13-a3dd-0d6fc1de2550",
   "metadata": {},
   "source": [
    "**2-PCA ve LDA Uygulaması**\n",
    "<br>PCA (Principal Component Analysis) ve LDA (Linear Discriminant Analysis) iki popüler boyut indirgeme tekniğidir. PCA, verinin varyansını maksimize ederek özellikleri dönüştürürken, LDA sınıf ayrımını maksimize eder. Her iki yöntem de genellikle yüksek boyutlu veri setlerini daha az boyutlu bir uzaya indirgemek için kullanılır. Ancak, LDA denetimli bir öğrenme yöntemidir ve sınıf etiketlerini kullanır, PCA ise denetimsiz bir yöntemdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35a9b12-7799-489c-9116-036b347b8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Açıklanan Varyans Oranı: [0.31192249 0.21186663]\n",
      "LDA Açıklanan Varyans Oranı: [1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_normalized.drop('Outcome', axis=1)\n",
    "y = df_normalized['Outcome']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "lda = LDA(n_components=1) \n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "print(\"PCA Açıklanan Varyans Oranı:\", pca.explained_variance_ratio_)\n",
    "print(\"LDA Açıklanan Varyans Oranı:\", lda.explained_variance_ratio_ if hasattr(lda, 'explained_variance_ratio_') else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1e4b-3ea2-4e42-b567-8e110afa5f75",
   "metadata": {},
   "source": [
    "PCA ve LDA sonuçlarına dayanarak, Insulin ve Glucose özelliklerinin bu veri seti için önemli olduğunu söyleyebiliriz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf434844-d675-40c0-a99f-b9b777a8932a",
   "metadata": {},
   "source": [
    "**3. Çoklu Doğrusal ve Multinominal Lojistik Regresyon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e9dfda-9cc1-450b-a67b-6802a08ed896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katsayılar:\n",
      " [[ 0.4505206   2.65118931 -0.24999553  0.03039025 -0.06304149  2.16599472\n",
      "   0.45399225  0.90638614]]\n",
      "Kesme terimi: [-3.25065341]\n",
      "Doğruluk oranı: 0.7359307359307359\n",
      "Sınıflandırma raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       151\n",
      "         1.0       0.63      0.57      0.60        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.70      0.70       231\n",
      "weighted avg       0.73      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Veri setini eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Lojistik Regresyon modeli eğitimi\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Modelin katsayılarını yazdırma\n",
    "print(\"Katsayılar:\\n\", log_reg.coef_)\n",
    "print(\"Kesme terimi:\", log_reg.intercept_)\n",
    "\n",
    "# Test verisi üzerinde performans değerlendirme\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Doğruluk oranı:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Sınıflandırma raporu:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df4bb0-6735-4a6f-9bda-d94c6b7e704c",
   "metadata": {},
   "source": [
    "Bu sonuçlar, modelin diyabet teşhisi konusunda iyi bir doğruluk oranına sahip olduğunu, ancak özellikle pozitif sınıf için (diyabet olanlar) duyarlılık ve kesinliğin daha da iyileştirilebileceğini göstermektedir. Yanlış negatif ve yanlış pozitif oranlarının azaltılması için modelin daha da optimize edilmesi gerekebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b7e96-5187-4a46-af29-6aa9e14d1eaa",
   "metadata": {},
   "source": [
    "**4. Karar Ağacı Sınıflandırma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dabd6c-9341-4995-b95c-b87b9f6bd07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk (Accuracy): 0.7012987012987013\n",
      "Confusion Matrix:\n",
      " [[107  44]\n",
      " [ 25  55]]\n",
      "Sınıflandırma Raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.71      0.76       151\n",
      "         1.0       0.56      0.69      0.61        80\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.68      0.70      0.69       231\n",
      "weighted avg       0.72      0.70      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Karar Ağacı modelini eğitme\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Test veri seti üzerinde modelin performansını değerlendirme\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "class_report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Doğruluk (Accuracy):\", accuracy_dt)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_dt)\n",
    "print(\"Sınıflandırma Raporu:\\n\", class_report_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994c2a9-01da-4957-83f7-9002ef9b4b6c",
   "metadata": {},
   "source": [
    "Karar Ağacı modeli, diyabet teşhisi konusunda kabul edilebilir bir doğruluk oranı sunmuş, ancak yanlış pozitif ve yanlış negatif oranları dikkate alındığında modelin performansının daha da iyileştirilebileceği görülmektedir. Diyabet olmayanları tespit etme konusunda daha yüksek bir kesinlik sunarken, diyabet olan hastaların tespitinde duyarlılığı artırılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69b539-c0fe-4382-a693-5c3bda0d2ebb",
   "metadata": {},
   "source": [
    "**5. Naive Bayes Sınıflandırma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec20807a-0795-4b82-835c-59d90aeeacd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk oranı: 0.7445887445887446\n",
      "Confusion Matrix:\n",
      " [[119  32]\n",
      " [ 27  53]]\n",
      "Sınıflandırma raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.80       151\n",
      "         1.0       0.62      0.66      0.64        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Naive Bayes modeli eğitimi\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Test verisi üzerinde performans değerlendirme\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "print(\"Doğruluk oranı:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"Sınıflandırma raporu:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fc756-355b-4a7a-aba8-30a772596d5d",
   "metadata": {},
   "source": [
    "Naive Bayes modeli, test verisi üzerinde %74.46 gibi bir doğruluk oranı ile kabul edilebilir bir performans göstermiştir. Model, diyabet olmayanları oldukça iyi bir kesinlikle tanırken, diyabet olan hastaların tespitinde duyarlılığı ve kesinliği daha da artırılabilir. Bu sonuçlar, modelin iyileştirilmesi için ek parametre ayarlamaları veya farklı sınıflandırma yöntemlerinin denenmesi gerektiğini göstermektedir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
